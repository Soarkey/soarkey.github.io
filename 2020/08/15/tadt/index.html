<!-- - var pageTitle = page.title || config.subtitle || ''--><!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="TADT"><meta name="keywords" content="Siamese network,VGG-16"><meta name="author" content="Soarkey,soarkey@foxmail.com"><meta name="copyright" content="Soarkey"><title>TADT | Soarkey's Blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.7.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.7.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js"></script><script src="https://cdn.jsdelivr.net/npm/blueimp-md5@2.10.0/js/md5.min.js"></script><link rel="manifest" href="/manifest.json"><link rel="manifest" href="/manifest.json"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://v1.hitokoto.cn/?encode=js&amp;charset=utf-8&amp;select=.footer_custom_text" defer></script><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script><meta name="generator" content="Hexo 4.2.1"></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#abstract"><span class="toc-text"> Abstract</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#1-introduction"><span class="toc-text"> 1. Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-method"><span class="toc-text"> 2. Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#21-features-of-the-pre-trained-cnns"><span class="toc-text"> 2.1 Features of the pre-trained CNNs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#22-target-active-features-via-regression"><span class="toc-text"> 2.2 Target-Active Features via Regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#23-scale-sensitive-features-via-ranking"><span class="toc-text"> 2.3 Scale-Sensitive Features via Ranking</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-tracking-process"><span class="toc-text"> 3. Tracking Process</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#31-tracker-initialization"><span class="toc-text"> 3.1 Tracker initialization</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#32-online-detection"><span class="toc-text"> 3.2 Online detection</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#33-scale-evaluation"><span class="toc-text"> 3.3 Scale evaluation</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-experiments"><span class="toc-text"> 4. Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#41-results"><span class="toc-text"> 4.1 Results</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#42-ablation-studies"><span class="toc-text"> 4.2 Ablation Studies</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://avatars3.githubusercontent.com/u/17349395?s=400&amp;u=b4d8f5e790e0fab115d7237ee3404f24813e115b&amp;v=4"></div><div class="author-info__name text-center">Soarkey</div><div class="author-info__description text-center">Soarkey's Blog</div><div class="follow-button"><a href="https://github.com/Soarkey">Follow Me</a></div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">21</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">20</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">17</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://github.com/Soarkey">github</a></div></div></div><div id="content-outer"><div id="top-container" style="background-image: url(https://github.com/Soarkey/soarkey.github.io/blob/master/img/bg.png?raw=true)"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Soarkey's Blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a><a class="site-page" href="/about">About</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a></span></div><div id="post-info"><div id="post-title">TADT</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2020-08-15</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Siamese-network/">Siamese network</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">775</span><span class="post-meta__separator">|</span><span>Reading time: 4 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><blockquote>
<p><img src="/2020/08/15/tadt/image-20200814163023573.png" alt="author"></p>
<p>📄 paper: <a href="https://arxiv.org/pdf/1904.01772.pdf">https://arxiv.org/pdf/1904.01772.pdf</a></p>
<p>💻 code: <a href="https://github.com/ZikunZhou/TADT-python">https://github.com/ZikunZhou/TADT-python</a></p>
<p>🌟  CVPR 2019</p>
</blockquote>
<a id="more"></a>
<h1 id="abstract"><a class="markdownIt-Anchor" href="#abstract"></a> Abstract</h1>
<p>[提出对预训练模型的质疑，关注特征提取的部分]</p>
<p>​	Despite demonstrated successes for numerous vision tasks, the contributions of using pre-trained deep features for visual tracking are not as significant as<br>
that for object recognition.</p>
<p><strong>key issue :</strong></p>
<ul>
<li>
<p>in visual tracking, the targets of interest can be <mark>arbitrary object class with arbitrary forms</mark>.</p>
</li>
<li>
<p>pre-trained deep features are less effective in modeling these targets of arbitrary forms for distinguishing them from the background.</p>
</li>
</ul>
<p><strong>Contribution:</strong></p>
<ul>
<li>a novel scheme to learn <mark>target-aware features</mark>.<br>
(which can better recognize the targets undergoing significant appearance variations than pre-trained deep features.)</li>
<li>develop a <mark>regression loss</mark> and a <mark>ranking loss</mark> to guide the generation of <mark>target-active and scale-sensitive features</mark>.</li>
</ul>
<blockquote>
<p>是否可以理解为本质上是通道间的注意力？</p>
</blockquote>
<h1 id="1-introduction"><a class="markdownIt-Anchor" href="#1-introduction"></a> 1. Introduction</h1>
<p><strong>target:</strong> learn target-aware deep features.</p>
<p>​	The gradients obtained through back-propagating a classification neural network indicate <mark>class-specific saliency well</mark>[33]. (特定类别的显著性)  With the use of <strong>global average pooling</strong>, the gradients generated by a convolutional filter can determine the importance of a filter for representing target objects.</p>
<blockquote>
<p>[33]： Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</p>
<ul>
<li>
<p>paper: <a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">https://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf</a></p>
</li>
<li>
<p>supp: <a href="https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_supplemental.zip">https://openaccess.thecvf.com/content_ICCV_2017/supplemental/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_supplemental.zip</a></p>
</li>
<li>
<p>code:  <a href="https://github.com/ramprs/grad-cam/">https://github.com/ramprs/grad-cam/</a></p>
</li>
<li>
<p>blog: <a href="https://blog.csdn.net/u013738531/article/details/81322043">https://blog.csdn.net/u013738531/article/details/81322043</a></p>
</li>
</ul>
  <img src="/2020/08/15/tadt/687474703a2f2f692e696d6775722e636f6d2f4a614762645a352e706e67.jpg" alt="Grad-CAM framework" style="zoom: 50%;">
  <img src="/2020/08/15/tadt/image-20200815145435355.png" alt="Grad-CAM" style="zoom:70%;">
</blockquote>
<p><strong>two types of objective losses:</strong></p>
<ul>
<li><strong>hinge loss</strong><br>
to regress pre-trained deep features to soft labels generated by a Gaussian function,<br>
use the gradients to select the target-active convolutional filters.</li>
<li><strong>ranking loss</strong><br>
with pair-wise distance to search for the scale-aware convolutional filters.</li>
</ul>
<p><strong>target-aware features vs. original deep features:</strong></p>
<blockquote>
<p>这个绘图的思路很特别，使用了t-SNE降维。</p>
<p>target-aware可以扩大类内和类间的距离（即区分度更高）</p>
</blockquote>
<p><img src="/2020/08/15/tadt/image-20200815150801070.png" alt="target-aware features vs. original deep features"></p>
<h1 id="2-method"><a class="markdownIt-Anchor" href="#2-method"></a> 2. Method</h1>
<h2 id="21-features-of-the-pre-trained-cnns"><a class="markdownIt-Anchor" href="#21-features-of-the-pre-trained-cnns"></a> 2.1 Features of the pre-trained CNNs</h2>
<p><strong>issues:</strong></p>
<ul>
<li>the pre-trained CNN features are agnostic of the semantic and objectness information of  the target, which most likely does not appear in the offline training data. (追踪需要处理任何对象标签的目标)</li>
<li>the pre-trained CNNs focus on increasing inter-class differences and the extracted deep features are insensitive to intra-class variations. （对类间的不同更敏感，对类内的变化不敏感）</li>
<li>the pre-trained deep features are sparsely activated by each category label especially in a deeper convolutional network. （预训练的深度特征被每个类别标签稀疏激活，即类别间的差异主要和少数特征有关；当用于追踪时，只有少部分被激活，会增加计算量，导致过拟合）</li>
</ul>
<p>​	Based on the <mark>gradient-based guidance</mark>, we construct a target-aware feature model with losses designed specifically for visual tracking.</p>
<h2 id="22-target-active-features-via-regression"><a class="markdownIt-Anchor" href="#22-target-active-features-via-regression"></a> 2.2 Target-Active Features via Regression</h2>
<p><img src="/2020/08/15/tadt/image-20200815161519345.png" alt="formula"></p>
<p><img src="/2020/08/15/tadt/image-20200815161545940.png" alt="formula"></p>
<p>如Fig.4©</p>
<p><img src="/2020/08/15/tadt/image-20200815161443754.png" alt="visualization"></p>
<h2 id="23-scale-sensitive-features-via-ranking"><a class="markdownIt-Anchor" href="#23-scale-sensitive-features-via-ranking"></a> 2.3 Scale-Sensitive Features via Ranking</h2>
<p><img src="/2020/08/15/tadt/image-20200815164732365.png" alt="formula"></p>
<p><img src="/2020/08/15/tadt/image-20200815164756633.png" alt="formula"></p>
<p><img src="/2020/08/15/tadt/image-20200815164830005.png" alt="formula"></p>
<h1 id="3-tracking-process"><a class="markdownIt-Anchor" href="#3-tracking-process"></a> 3. Tracking Process</h1>
<p><strong>overall framework:</strong></p>
<p><img src="/2020/08/15/tadt/image-20200815155629771.png" alt="architecture"></p>
<h2 id="31-tracker-initialization"><a class="markdownIt-Anchor" href="#31-tracker-initialization"></a> 3.1 Tracker initialization</h2>
<ul>
<li>The pre-trained feature extractor is offline trained on the classification task.</li>
<li><mark>the target-aware part is only trained in the first frame.</mark></li>
</ul>
<p>​	In initial training, the regression loss and the ranking loss parts are trained separately and we compute the gradients from each loss once the networks are converged. With the gradients, the feature generation model selects a fixed number of the filters with the highest importance scores from the pre-trained CNNs.</p>
<p>​	The final target-aware features are obtained by stacking these two types of feature filters. Considering the scalar difference, these two types of features are <mark>re-scaled by dividing their maximal channel summation</mark> (summation of all the values in one channel).</p>
<blockquote>
<p>具体操作存在疑问</p>
</blockquote>
<h2 id="32-online-detection"><a class="markdownIt-Anchor" href="#32-online-detection"></a> 3.2 Online detection</h2>
<p><img src="/2020/08/15/tadt/image-20200815170343327.png" alt="formula"></p>
<h2 id="33-scale-evaluation"><a class="markdownIt-Anchor" href="#33-scale-evaluation"></a> 3.3 Scale evaluation</h2>
<p>​	To evaluate the scale change of the target, we fix the size of the template and re-scale the feature map of the search region in the current frame to smaller,<br>
larger, and fixed ones. During tracking, all these three feature maps are compared with the target template. The scale evaluation is performed by finding the score map containing the highest response.</p>
<h1 id="4-experiments"><a class="markdownIt-Anchor" href="#4-experiments"></a> 4. Experiments</h1>
<h2 id="41-results"><a class="markdownIt-Anchor" href="#41-results"></a> 4.1 Results</h2>
<p><img src="/2020/08/15/tadt/image-20200815195043731.png" alt="experiments"></p>
<p><img src="/2020/08/15/tadt/image-20200815195144776.png" alt="OTB"></p>
<p><img src="/2020/08/15/tadt/image-20200815195210762.png" alt="VOT"></p>
<p><img src="/2020/08/15/tadt/image-20200815195235715.png" alt="TC-128"></p>
<h2 id="42-ablation-studies"><a class="markdownIt-Anchor" href="#42-ablation-studies"></a> 4.2 Ablation Studies</h2>
<p><img src="/2020/08/15/tadt/image-20200815195330938.png" alt="ablation study"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:soarkey@foxmail.com">Soarkey</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="https://soarkey.github.io/2020/08/15/tadt/">https://soarkey.github.io/2020/08/15/tadt/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Siamese-network/">Siamese network</a><a class="post-meta__tags" href="/tags/VGG-16/">VGG-16</a></div><div class="social-share pull-right"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js@1.0.16/dist/js/social-share.min.js"></script><nav id="pagination"><div class="prev-post pull-left"><a href="/2020/08/23/dasiamrpn/"><i class="fa fa-chevron-left">  </i><span>DaSiamRPN</span></a></div><div class="next-post pull-right"><a href="/2020/08/09/ocean/"><span>Ocean</span><i class="fa fa-chevron-right"></i></a></div></nav><div id="gitalk-container"></div><script>var gitalk = new Gitalk({
  clientID: 'c1c26b093ab018134968',
  clientSecret: 'b85a3a9d5e48dfc88343b4f40fced48e46e522e0',
  repo: 'soarkey.github.io',
  owner: 'Soarkey',
  admin: 'Soarkey',
  id: md5(decodeURI(location.pathname)),
  language: 'en'
})
gitalk.render('gitalk-container')</script></div></div><footer class="footer-bg" style="background-image: url(https://github.com/Soarkey/soarkey.github.io/blob/master/img/bg.png?raw=true)"><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2021 By Soarkey</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="footer_custom_text">hitokoto</div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.7.0"></script><script src="/js/fancybox.js?version=1.7.0"></script><script src="/js/sidebar.js?version=1.7.0"></script><script src="/js/copy.js?version=1.7.0"></script><script src="/js/fireworks.js?version=1.7.0"></script><script src="/js/transition.js?version=1.7.0"></script><script src="/js/scroll.js?version=1.7.0"></script><script src="/js/head.js?version=1.7.0"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script src="/js/katex.js"></script><script src="/js/search/local-search.js"></script><script id="ribbon" src="/js/third-party/canvas-ribbon.js" size="150" alpha="0.2" zIndex="-1" data-click="true"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>